{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8863918,"sourceType":"datasetVersion","datasetId":5335373}],"dockerImageVersionId":30733,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Path to the directory containing images\nimage_dir = '/kaggle/input/machine-learning-project-data/all_words'\n\n# List all files in the directory\nimage_files = os.listdir(image_dir)\n\n# Filter out only image files (optional, if needed)\nimage_files = [file for file in image_files if file.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n\n# Load and display the first image\nif image_files:\n    first_image_path = os.path.join(image_dir, image_files[0])\n    image = Image.open(first_image_path)\n\n    # Display the image\n    plt.imshow(image)\n    plt.axis('off')  # Hide axes\n    plt.show()\n\n    # Print image details\n    print(f\"Image size: {image.size}\")\n    print(f\"Image format: {image.format}\")\nelse:\n    print(\"No images found in the directory.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-05T05:59:17.945102Z","iopub.execute_input":"2024-07-05T05:59:17.945795Z","iopub.status.idle":"2024-07-05T05:59:19.306020Z","shell.execute_reply.started":"2024-07-05T05:59:17.945762Z","shell.execute_reply":"2024-07-05T05:59:19.305102Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Image size: (107, 100)\nImage format: PNG\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\n\n# Path to the directory containing images\nimage_dir = '/kaggle/input/machine-learning-project-data/all_words'\n\n# List all files in the directory\nimage_files = os.listdir(image_dir)\n\n# Filter out only image files (optional, if needed)\nimage_files = [file for file in image_files if file.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n\n# Load all images into a list\nimages = []\nfor image_file in image_files:\n    image_path = os.path.join(image_dir, image_file)\n    image = Image.open(image_path)\n    images.append(image)\n\n# Display the number of images loaded\nprint(f\"Loaded {len(images)} images.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T06:34:35.672307Z","iopub.execute_input":"2024-07-05T06:34:35.673244Z","iopub.status.idle":"2024-07-05T06:45:52.340540Z","shell.execute_reply.started":"2024-07-05T06:34:35.673208Z","shell.execute_reply":"2024-07-05T06:45:52.339443Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Loaded 175760 images.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom keras.utils import to_categorical\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\n# Function to load filenames and preprocess labels\ndef load_and_preprocess_labels(image_dir):\n    labels = []\n    filenames = []\n    for filename in os.listdir(image_dir):\n        if filename.endswith('.png'):\n            parts = filename.split('_')\n            label = '_'.join(parts[:4])\n            labels.append(label)\n            filenames.append(filename)\n    return filenames, labels\n\n# Function to load images\ndef load_images(image_dir, filenames):\n    images = []\n    for filename in filenames:\n        img_path = os.path.join(image_dir, filename)\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (128, 32))\n        images.append(img)\n    return np.array(images)\n\n# Path to your dataset directory\nimage_dir = '/kaggle/input/machine-learning-project-data/all_words'\n\n# Load and preprocess labels\nfilenames, labels = load_and_preprocess_labels(image_dir)\n\n# Encode labels\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels)\n\n# Load images\nimages = load_images(image_dir, filenames)\n\n# Normalize images\nimages = images / 255.0\nimages = images.reshape(-1, 32, 128, 1)\n\n# Use only the first 150000 images\nimages = images[:15000]\nencoded_labels = encoded_labels[:15000]\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(images, encoded_labels, test_size=0.2, random_state=42)\n\n# Define the CNN model\ndef create_cnn_model(input_shape, num_classes):\n    model = Sequential([\n        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu'),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu'),\n        MaxPooling2D((2, 2)),\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')\n    ])\n    return model\n\n# Create the model\ninput_shape = (32, 128, 1)\nnum_classes = len(np.unique(encoded_labels))  # Number of unique classes\nmodel = create_cnn_model(input_shape, num_classes)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(X_val, y_val)\nprint('Test Accuracy:', test_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T08:07:33.226621Z","iopub.execute_input":"2024-07-05T08:07:33.227642Z","iopub.status.idle":"2024-07-05T08:11:59.343218Z","shell.execute_reply.started":"2024-07-05T08:07:33.227604Z","shell.execute_reply":"2024-07-05T08:11:59.342172Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m 31/375\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0095 - loss: 5.1564","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720167033.954998     217 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m369/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0089 - loss: 5.1313","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720167036.144392     219 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0090 - loss: 5.1308 - val_accuracy: 0.0297 - val_loss: 4.9085\nEpoch 2/50\n\u001b[1m 41/375\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0274 - loss: 4.9016","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720167037.030868     219 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0403 - loss: 4.6675 - val_accuracy: 0.2027 - val_loss: 3.6886\nEpoch 3/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1297 - loss: 3.8027 - val_accuracy: 0.3483 - val_loss: 2.9575\nEpoch 4/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2169 - loss: 3.2579 - val_accuracy: 0.4460 - val_loss: 2.5080\nEpoch 5/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3088 - loss: 2.7783 - val_accuracy: 0.5167 - val_loss: 2.1274\nEpoch 6/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3524 - loss: 2.5091 - val_accuracy: 0.5500 - val_loss: 1.8918\nEpoch 7/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4011 - loss: 2.2693 - val_accuracy: 0.5827 - val_loss: 1.7056\nEpoch 8/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4233 - loss: 2.1080 - val_accuracy: 0.6230 - val_loss: 1.5503\nEpoch 9/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4746 - loss: 1.8874 - val_accuracy: 0.6350 - val_loss: 1.4090\nEpoch 10/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4890 - loss: 1.8063 - val_accuracy: 0.6653 - val_loss: 1.3439\nEpoch 11/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5060 - loss: 1.7256 - val_accuracy: 0.6693 - val_loss: 1.2621\nEpoch 12/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5250 - loss: 1.6259 - val_accuracy: 0.6833 - val_loss: 1.2032\nEpoch 13/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5275 - loss: 1.5873 - val_accuracy: 0.6927 - val_loss: 1.1705\nEpoch 14/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5584 - loss: 1.4934 - val_accuracy: 0.7103 - val_loss: 1.1215\nEpoch 15/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5640 - loss: 1.4634 - val_accuracy: 0.7087 - val_loss: 1.0783\nEpoch 16/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5854 - loss: 1.3601 - val_accuracy: 0.7037 - val_loss: 1.0711\nEpoch 17/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5991 - loss: 1.3359 - val_accuracy: 0.7280 - val_loss: 1.0182\nEpoch 18/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6036 - loss: 1.2934 - val_accuracy: 0.7327 - val_loss: 1.0034\nEpoch 19/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6138 - loss: 1.2547 - val_accuracy: 0.7257 - val_loss: 0.9839\nEpoch 20/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6121 - loss: 1.2391 - val_accuracy: 0.7400 - val_loss: 0.9401\nEpoch 21/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6284 - loss: 1.1865 - val_accuracy: 0.7350 - val_loss: 0.9306\nEpoch 22/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6354 - loss: 1.1419 - val_accuracy: 0.7537 - val_loss: 0.9101\nEpoch 23/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6489 - loss: 1.1195 - val_accuracy: 0.7443 - val_loss: 0.9269\nEpoch 24/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6640 - loss: 1.0641 - val_accuracy: 0.7603 - val_loss: 0.8860\nEpoch 25/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6581 - loss: 1.0750 - val_accuracy: 0.7580 - val_loss: 0.8889\nEpoch 26/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6701 - loss: 1.0468 - val_accuracy: 0.7670 - val_loss: 0.8377\nEpoch 27/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6713 - loss: 1.0299 - val_accuracy: 0.7690 - val_loss: 0.8478\nEpoch 28/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6754 - loss: 1.0320 - val_accuracy: 0.7740 - val_loss: 0.8304\nEpoch 29/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6841 - loss: 0.9803 - val_accuracy: 0.7710 - val_loss: 0.8443\nEpoch 30/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6911 - loss: 0.9612 - val_accuracy: 0.7823 - val_loss: 0.8130\nEpoch 31/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6884 - loss: 0.9569 - val_accuracy: 0.7760 - val_loss: 0.8201\nEpoch 32/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7037 - loss: 0.9400 - val_accuracy: 0.7760 - val_loss: 0.8224\nEpoch 33/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.9088 - val_accuracy: 0.7757 - val_loss: 0.8394\nEpoch 34/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7069 - loss: 0.9025 - val_accuracy: 0.7857 - val_loss: 0.7990\nEpoch 35/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7105 - loss: 0.8780 - val_accuracy: 0.7820 - val_loss: 0.8070\nEpoch 36/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7165 - loss: 0.8810 - val_accuracy: 0.7937 - val_loss: 0.7679\nEpoch 37/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 0.8535 - val_accuracy: 0.7847 - val_loss: 0.7800\nEpoch 38/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7299 - loss: 0.8419 - val_accuracy: 0.7947 - val_loss: 0.7933\nEpoch 39/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7392 - loss: 0.8093 - val_accuracy: 0.7943 - val_loss: 0.7689\nEpoch 40/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7341 - loss: 0.7998 - val_accuracy: 0.7890 - val_loss: 0.7962\nEpoch 41/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7356 - loss: 0.7942 - val_accuracy: 0.7930 - val_loss: 0.7538\nEpoch 42/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7383 - loss: 0.7875 - val_accuracy: 0.8000 - val_loss: 0.7492\nEpoch 43/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7456 - loss: 0.7626 - val_accuracy: 0.7967 - val_loss: 0.7761\nEpoch 44/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7405 - loss: 0.7905 - val_accuracy: 0.8057 - val_loss: 0.7507\nEpoch 45/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7510 - loss: 0.7492 - val_accuracy: 0.7960 - val_loss: 0.7704\nEpoch 46/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7542 - loss: 0.7583 - val_accuracy: 0.8070 - val_loss: 0.7508\nEpoch 47/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.7629 - val_accuracy: 0.8067 - val_loss: 0.7548\nEpoch 48/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7501 - loss: 0.7444 - val_accuracy: 0.8067 - val_loss: 0.7341\nEpoch 49/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7618 - loss: 0.7165 - val_accuracy: 0.8090 - val_loss: 0.7431\nEpoch 50/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.7115 - val_accuracy: 0.8030 - val_loss: 0.7511\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.6799\nTest Accuracy: 0.8029999732971191\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.callbacks import Callback\n\n# Function to load filenames and preprocess labels\ndef load_and_preprocess_labels(image_dir):\n    labels = []\n    filenames = []\n    for filename in os.listdir(image_dir):\n        if filename.endswith('.png'):\n            parts = filename.split('_')\n            label = '_'.join(parts[:4])\n            labels.append(label)\n            filenames.append(filename)\n    return filenames, labels\n\n# Function to load images\ndef load_images(image_dir, filenames):\n    images = []\n    for filename in filenames:\n        img_path = os.path.join(image_dir, filename)\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (128, 32))\n        images.append(img)\n    return np.array(images)\n\n# Path to your dataset directory\nimage_dir = '/kaggle/input/machine-learning-project-data/all_words'\n\n# Load and preprocess labels\nfilenames, labels = load_and_preprocess_labels(image_dir)\n\n# Encode labels\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels)\n\n# Load images\nimages = load_images(image_dir, filenames)\n\n# Normalize images\nimages = images / 255.0\nimages = images.reshape(-1, 32, 128, 1)\n\n# Use only the first 15000 images\nimages = images[:15000]\nencoded_labels = encoded_labels[:15000]\n\n# Split data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(images, encoded_labels, test_size=0.2, random_state=42)\n\n# Define the CNN model\ndef create_cnn_model(input_shape, num_classes):\n    model = Sequential([\n        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu'),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu'),\n        MaxPooling2D((2, 2)),\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')\n    ])\n    return model\n\n# Create the model\ninput_shape = (32, 128, 1)\nnum_classes = len(np.unique(encoded_labels))  # Number of unique classes\nmodel = create_cnn_model(input_shape, num_classes)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Define a callback to print validation accuracy\nclass ValidationCallback(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        val_loss, val_accuracy = self.model.evaluate(X_val, y_val, verbose=0)\n        print(f\"Validation Accuracy after epoch {epoch + 1}: {val_accuracy:.4f}\")\n\n# Train the model with the callback\nhistory = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[ValidationCallback()])\n\n# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(X_val, y_val)\nprint(f'Test Accuracy: {test_accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T08:17:51.799275Z","iopub.execute_input":"2024-07-05T08:17:51.800116Z","iopub.status.idle":"2024-07-05T08:22:42.763333Z","shell.execute_reply.started":"2024-07-05T08:17:51.800079Z","shell.execute_reply":"2024-07-05T08:22:42.762294Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m 42/375\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0022 - loss: 5.1454  ","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720167665.034839     218 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0058 - loss: 5.1337","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720167667.134975     217 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1720167667.863166     217 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy after epoch 1: 0.0037\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.0058 - loss: 5.1337 - val_accuracy: 0.0037 - val_loss: 5.1294\nEpoch 2/50\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0137 - loss: 5.0375Validation Accuracy after epoch 2: 0.0523\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0138 - loss: 5.0365 - val_accuracy: 0.0523 - val_loss: 4.3538\nEpoch 3/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0519 - loss: 4.2954Validation Accuracy after epoch 3: 0.1790\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0519 - loss: 4.2950 - val_accuracy: 0.1790 - val_loss: 3.5467\nEpoch 4/50\n\u001b[1m369/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1164 - loss: 3.6582Validation Accuracy after epoch 4: 0.2937\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1166 - loss: 3.6562 - val_accuracy: 0.2937 - val_loss: 2.8484\nEpoch 5/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1762 - loss: 3.1680Validation Accuracy after epoch 5: 0.4047\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1762 - loss: 3.1678 - val_accuracy: 0.4047 - val_loss: 2.3606\nEpoch 6/50\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2414 - loss: 2.8095Validation Accuracy after epoch 6: 0.4810\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2414 - loss: 2.8093 - val_accuracy: 0.4810 - val_loss: 2.0225\nEpoch 7/50\n\u001b[1m363/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2834 - loss: 2.5855Validation Accuracy after epoch 7: 0.5187\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2838 - loss: 2.5841 - val_accuracy: 0.5187 - val_loss: 1.8599\nEpoch 8/50\n\u001b[1m370/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3275 - loss: 2.3939Validation Accuracy after epoch 8: 0.5607\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3275 - loss: 2.3936 - val_accuracy: 0.5607 - val_loss: 1.6462\nEpoch 9/50\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3587 - loss: 2.2271Validation Accuracy after epoch 9: 0.5870\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3587 - loss: 2.2272 - val_accuracy: 0.5870 - val_loss: 1.5219\nEpoch 10/50\n\u001b[1m364/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3803 - loss: 2.1074Validation Accuracy after epoch 10: 0.6193\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3803 - loss: 2.1079 - val_accuracy: 0.6193 - val_loss: 1.3937\nEpoch 11/50\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4125 - loss: 1.9777Validation Accuracy after epoch 11: 0.6513\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4124 - loss: 1.9778 - val_accuracy: 0.6513 - val_loss: 1.3420\nEpoch 12/50\n\u001b[1m364/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4283 - loss: 1.9211Validation Accuracy after epoch 12: 0.6540\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4282 - loss: 1.9211 - val_accuracy: 0.6540 - val_loss: 1.2497\nEpoch 13/50\n\u001b[1m366/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4326 - loss: 1.8875Validation Accuracy after epoch 13: 0.6800\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4328 - loss: 1.8866 - val_accuracy: 0.6800 - val_loss: 1.1975\nEpoch 14/50\n\u001b[1m366/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4598 - loss: 1.7766Validation Accuracy after epoch 14: 0.6870\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4597 - loss: 1.7770 - val_accuracy: 0.6870 - val_loss: 1.1733\nEpoch 15/50\n\u001b[1m369/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4780 - loss: 1.7210Validation Accuracy after epoch 15: 0.7087\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4780 - loss: 1.7208 - val_accuracy: 0.7087 - val_loss: 1.0497\nEpoch 16/50\n\u001b[1m369/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4822 - loss: 1.6747Validation Accuracy after epoch 16: 0.7190\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4823 - loss: 1.6744 - val_accuracy: 0.7190 - val_loss: 0.9858\nEpoch 17/50\n\u001b[1m366/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5008 - loss: 1.5938Validation Accuracy after epoch 17: 0.7010\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5009 - loss: 1.5937 - val_accuracy: 0.7010 - val_loss: 0.9825\nEpoch 18/50\n\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5218 - loss: 1.5413Validation Accuracy after epoch 18: 0.7217\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5217 - loss: 1.5415 - val_accuracy: 0.7217 - val_loss: 0.9478\nEpoch 19/50\n\u001b[1m371/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5297 - loss: 1.4919Validation Accuracy after epoch 19: 0.7450\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5297 - loss: 1.4923 - val_accuracy: 0.7450 - val_loss: 0.8949\nEpoch 20/50\n\u001b[1m363/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5461 - loss: 1.4552Validation Accuracy after epoch 20: 0.7553\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5459 - loss: 1.4557 - val_accuracy: 0.7553 - val_loss: 0.8511\nEpoch 21/50\n\u001b[1m369/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5442 - loss: 1.4409Validation Accuracy after epoch 21: 0.7600\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5442 - loss: 1.4408 - val_accuracy: 0.7600 - val_loss: 0.8426\nEpoch 22/50\n\u001b[1m371/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5573 - loss: 1.3969Validation Accuracy after epoch 22: 0.7570\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5572 - loss: 1.3971 - val_accuracy: 0.7570 - val_loss: 0.8417\nEpoch 23/50\n\u001b[1m365/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5793 - loss: 1.3408Validation Accuracy after epoch 23: 0.7650\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5792 - loss: 1.3413 - val_accuracy: 0.7650 - val_loss: 0.7977\nEpoch 24/50\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5756 - loss: 1.3258Validation Accuracy after epoch 24: 0.7617\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5756 - loss: 1.3258 - val_accuracy: 0.7617 - val_loss: 0.7898\nEpoch 25/50\n\u001b[1m362/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5767 - loss: 1.3119Validation Accuracy after epoch 25: 0.7807\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5768 - loss: 1.3116 - val_accuracy: 0.7807 - val_loss: 0.7322\nEpoch 26/50\n\u001b[1m363/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5981 - loss: 1.2401Validation Accuracy after epoch 26: 0.7747\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5980 - loss: 1.2402 - val_accuracy: 0.7747 - val_loss: 0.7576\nEpoch 27/50\n\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5988 - loss: 1.2308Validation Accuracy after epoch 27: 0.7780\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5988 - loss: 1.2307 - val_accuracy: 0.7780 - val_loss: 0.6949\nEpoch 28/50\n\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6193 - loss: 1.1825Validation Accuracy after epoch 28: 0.7963\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6192 - loss: 1.1828 - val_accuracy: 0.7963 - val_loss: 0.7076\nEpoch 29/50\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6183 - loss: 1.1702Validation Accuracy after epoch 29: 0.8000\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6183 - loss: 1.1703 - val_accuracy: 0.8000 - val_loss: 0.6857\nEpoch 30/50\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6291 - loss: 1.1293Validation Accuracy after epoch 30: 0.7870\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6291 - loss: 1.1294 - val_accuracy: 0.7870 - val_loss: 0.6789\nEpoch 31/50\n\u001b[1m362/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6284 - loss: 1.1266Validation Accuracy after epoch 31: 0.7930\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6285 - loss: 1.1267 - val_accuracy: 0.7930 - val_loss: 0.6808\nEpoch 32/50\n\u001b[1m364/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6476 - loss: 1.0683Validation Accuracy after epoch 32: 0.8057\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6474 - loss: 1.0688 - val_accuracy: 0.8057 - val_loss: 0.6448\nEpoch 33/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6575 - loss: 1.0386Validation Accuracy after epoch 33: 0.8097\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6575 - loss: 1.0386 - val_accuracy: 0.8097 - val_loss: 0.6307\nEpoch 34/50\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6605 - loss: 1.0414Validation Accuracy after epoch 34: 0.8233\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6605 - loss: 1.0414 - val_accuracy: 0.8233 - val_loss: 0.6035\nEpoch 35/50\n\u001b[1m367/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6711 - loss: 1.0240Validation Accuracy after epoch 35: 0.8007\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6710 - loss: 1.0240 - val_accuracy: 0.8007 - val_loss: 0.6469\nEpoch 36/50\n\u001b[1m362/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6760 - loss: 0.9727Validation Accuracy after epoch 36: 0.8163\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6759 - loss: 0.9729 - val_accuracy: 0.8163 - val_loss: 0.6100\nEpoch 37/50\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6790 - loss: 0.9751Validation Accuracy after epoch 37: 0.8413\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6791 - loss: 0.9749 - val_accuracy: 0.8413 - val_loss: 0.5645\nEpoch 38/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6916 - loss: 0.9195Validation Accuracy after epoch 38: 0.8293\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6916 - loss: 0.9196 - val_accuracy: 0.8293 - val_loss: 0.6184\nEpoch 39/50\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.8970Validation Accuracy after epoch 39: 0.8290\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7062 - loss: 0.8971 - val_accuracy: 0.8290 - val_loss: 0.5861\nEpoch 40/50\n\u001b[1m365/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6946 - loss: 0.9194Validation Accuracy after epoch 40: 0.8433\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6948 - loss: 0.9189 - val_accuracy: 0.8433 - val_loss: 0.5528\nEpoch 41/50\n\u001b[1m362/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7055 - loss: 0.8745Validation Accuracy after epoch 41: 0.8473\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7054 - loss: 0.8750 - val_accuracy: 0.8473 - val_loss: 0.5395\nEpoch 42/50\n\u001b[1m364/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7124 - loss: 0.8658Validation Accuracy after epoch 42: 0.8480\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7124 - loss: 0.8659 - val_accuracy: 0.8480 - val_loss: 0.5313\nEpoch 43/50\n\u001b[1m365/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7222 - loss: 0.8345Validation Accuracy after epoch 43: 0.8370\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.8348 - val_accuracy: 0.8370 - val_loss: 0.5550\nEpoch 44/50\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7311 - loss: 0.8201Validation Accuracy after epoch 44: 0.8450\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7311 - loss: 0.8201 - val_accuracy: 0.8450 - val_loss: 0.5303\nEpoch 45/50\n\u001b[1m364/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7294 - loss: 0.8146Validation Accuracy after epoch 45: 0.8593\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7293 - loss: 0.8150 - val_accuracy: 0.8593 - val_loss: 0.5002\nEpoch 46/50\n\u001b[1m365/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7462 - loss: 0.7678Validation Accuracy after epoch 46: 0.8590\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7462 - loss: 0.7678 - val_accuracy: 0.8590 - val_loss: 0.4899\nEpoch 47/50\n\u001b[1m362/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7357 - loss: 0.7842Validation Accuracy after epoch 47: 0.8567\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7357 - loss: 0.7844 - val_accuracy: 0.8567 - val_loss: 0.5245\nEpoch 48/50\n\u001b[1m371/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7409 - loss: 0.7760Validation Accuracy after epoch 48: 0.8663\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7409 - loss: 0.7760 - val_accuracy: 0.8663 - val_loss: 0.4728\nEpoch 49/50\n\u001b[1m370/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.7457Validation Accuracy after epoch 49: 0.8680\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7547 - loss: 0.7458 - val_accuracy: 0.8680 - val_loss: 0.4662\nEpoch 50/50\n\u001b[1m370/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7508 - loss: 0.7244Validation Accuracy after epoch 50: 0.8710\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7507 - loss: 0.7246 - val_accuracy: 0.8710 - val_loss: 0.4668\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.4705\nTest Accuracy: 0.8710\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.callbacks import Callback\n\ndef load_and_preprocess_labels(image_dir):\n    labels = []\n    filenames = []\n    for filename in os.listdir(image_dir):\n        if filename.endswith('.png'):\n            parts = filename.split('_')\n            label = '_'.join(parts[:4])\n            labels.append(label)\n            filenames.append(filename)\n    return filenames, labels\n\ndef load_images(image_dir, filenames):\n    images = []\n    for filename in filenames:\n        img_path = os.path.join(image_dir, filename)\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (128, 32))\n        images.append(img)\n    return np.array(images)\n\nimage_dir = '/kaggle/input/machine-learning-project-data/all_words'\n\nfilenames, labels = load_and_preprocess_labels(image_dir)\n\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels)\n\nimages = load_images(image_dir, filenames)\n\nimages = images / 255.0\nimages = images.reshape(-1, 32, 128, 1)\n\nimages = images[:15000]\nencoded_labels = encoded_labels[:15000]\n\nX_train, X_val, y_train, y_val = train_test_split(images, encoded_labels, test_size=0.2, random_state=42)\n\ndef create_cnn_model(input_shape, num_classes):\n    model = Sequential([\n        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D((2, 2)),\n        Conv2D(64, (3, 3), activation='relu', padding='same'),\n        MaxPooling2D((2, 2)),\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')\n    ])\n    return model\n\ninput_shape = (32, 128, 1)\nnum_classes = len(np.unique(encoded_labels))  # Number of unique classes\nmodel = create_cnn_model(input_shape, num_classes)\n\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nclass ValidationCallback(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        val_loss, val_accuracy = self.model.evaluate(X_val, y_val, verbose=0)\n        print(f\"Validation Accuracy after epoch {epoch + 1}: {val_accuracy:.4f}\")\n\nhistory = model.fit(X_train, y_train, epochs=60, batch_size=32, validation_data=(X_val, y_val), callbacks=[ValidationCallback()])\n\ntest_loss, test_accuracy = model.evaluate(X_val, y_val)\nprint(f'Test Accuracy: {test_accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T08:35:03.877689Z","iopub.execute_input":"2024-07-05T08:35:03.878534Z","iopub.status.idle":"2024-07-05T08:40:20.108988Z","shell.execute_reply.started":"2024-07-05T08:35:03.878497Z","shell.execute_reply":"2024-07-05T08:40:20.108005Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/60\n\u001b[1m 37/375\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0069 - loss: 5.1278","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720168689.751769     219 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0068 - loss: 5.1296","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720168692.151334     217 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1720168693.498668     220 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy after epoch 1: 0.0043\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.0068 - loss: 5.1296 - val_accuracy: 0.0043 - val_loss: 5.1306\nEpoch 2/60\n\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0072 - loss: 5.1278Validation Accuracy after epoch 2: 0.0103\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.0072 - loss: 5.1277 - val_accuracy: 0.0103 - val_loss: 5.0392\nEpoch 3/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0202 - loss: 4.8624Validation Accuracy after epoch 3: 0.0863\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.0202 - loss: 4.8610 - val_accuracy: 0.0863 - val_loss: 4.1604\nEpoch 4/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0734 - loss: 4.0889Validation Accuracy after epoch 4: 0.2793\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.0736 - loss: 4.0872 - val_accuracy: 0.2793 - val_loss: 2.9707\nEpoch 5/60\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1950 - loss: 3.1690Validation Accuracy after epoch 5: 0.4360\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1951 - loss: 3.1685 - val_accuracy: 0.4360 - val_loss: 2.1798\nEpoch 6/60\n\u001b[1m370/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3181 - loss: 2.4918Validation Accuracy after epoch 6: 0.5673\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3184 - loss: 2.4907 - val_accuracy: 0.5673 - val_loss: 1.7127\nEpoch 7/60\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3933 - loss: 2.1101Validation Accuracy after epoch 7: 0.6233\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3933 - loss: 2.1098 - val_accuracy: 0.6233 - val_loss: 1.4112\nEpoch 8/60\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4607 - loss: 1.8129Validation Accuracy after epoch 8: 0.6873\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4608 - loss: 1.8128 - val_accuracy: 0.6873 - val_loss: 1.1229\nEpoch 9/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5300 - loss: 1.5911Validation Accuracy after epoch 9: 0.7090\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5300 - loss: 1.5910 - val_accuracy: 0.7090 - val_loss: 1.0384\nEpoch 10/60\n\u001b[1m371/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5673 - loss: 1.4224Validation Accuracy after epoch 10: 0.7317\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5673 - loss: 1.4222 - val_accuracy: 0.7317 - val_loss: 0.9544\nEpoch 11/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6032 - loss: 1.2891Validation Accuracy after epoch 11: 0.7777\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6032 - loss: 1.2890 - val_accuracy: 0.7777 - val_loss: 0.7828\nEpoch 12/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6287 - loss: 1.1906Validation Accuracy after epoch 12: 0.7980\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6288 - loss: 1.1905 - val_accuracy: 0.7980 - val_loss: 0.7367\nEpoch 13/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6620 - loss: 1.0935Validation Accuracy after epoch 13: 0.8107\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6620 - loss: 1.0934 - val_accuracy: 0.8107 - val_loss: 0.6914\nEpoch 14/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6787 - loss: 1.0203Validation Accuracy after epoch 14: 0.8280\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6788 - loss: 1.0202 - val_accuracy: 0.8280 - val_loss: 0.6144\nEpoch 15/60\n\u001b[1m368/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7091 - loss: 0.9249Validation Accuracy after epoch 15: 0.8410\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7091 - loss: 0.9251 - val_accuracy: 0.8410 - val_loss: 0.5677\nEpoch 16/60\n\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7201 - loss: 0.8741Validation Accuracy after epoch 16: 0.8470\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7201 - loss: 0.8741 - val_accuracy: 0.8470 - val_loss: 0.5256\nEpoch 17/60\n\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7454 - loss: 0.7981Validation Accuracy after epoch 17: 0.8617\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7454 - loss: 0.7983 - val_accuracy: 0.8617 - val_loss: 0.4844\nEpoch 18/60\n\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7606 - loss: 0.7500Validation Accuracy after epoch 18: 0.8680\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7605 - loss: 0.7502 - val_accuracy: 0.8680 - val_loss: 0.4691\nEpoch 19/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7699 - loss: 0.7019Validation Accuracy after epoch 19: 0.8793\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7698 - loss: 0.7020 - val_accuracy: 0.8793 - val_loss: 0.4324\nEpoch 20/60\n\u001b[1m369/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7832 - loss: 0.6652Validation Accuracy after epoch 20: 0.8777\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7832 - loss: 0.6655 - val_accuracy: 0.8777 - val_loss: 0.4133\nEpoch 21/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7813 - loss: 0.6785Validation Accuracy after epoch 21: 0.8843\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7813 - loss: 0.6785 - val_accuracy: 0.8843 - val_loss: 0.3982\nEpoch 22/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7934 - loss: 0.6273Validation Accuracy after epoch 22: 0.8877\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7933 - loss: 0.6274 - val_accuracy: 0.8877 - val_loss: 0.3892\nEpoch 23/60\n\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.6098Validation Accuracy after epoch 23: 0.8913\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7990 - loss: 0.6099 - val_accuracy: 0.8913 - val_loss: 0.3772\nEpoch 24/60\n\u001b[1m371/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8173 - loss: 0.5563Validation Accuracy after epoch 24: 0.8867\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8173 - loss: 0.5564 - val_accuracy: 0.8867 - val_loss: 0.3922\nEpoch 25/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8200 - loss: 0.5452Validation Accuracy after epoch 25: 0.9000\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8200 - loss: 0.5452 - val_accuracy: 0.9000 - val_loss: 0.3366\nEpoch 26/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8328 - loss: 0.5100Validation Accuracy after epoch 26: 0.9013\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8328 - loss: 0.5101 - val_accuracy: 0.9013 - val_loss: 0.3172\nEpoch 27/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8422 - loss: 0.4783Validation Accuracy after epoch 27: 0.9057\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8422 - loss: 0.4785 - val_accuracy: 0.9057 - val_loss: 0.3209\nEpoch 28/60\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8421 - loss: 0.4798Validation Accuracy after epoch 28: 0.8820\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8421 - loss: 0.4798 - val_accuracy: 0.8820 - val_loss: 0.3914\nEpoch 29/60\n\u001b[1m371/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.4730Validation Accuracy after epoch 29: 0.9100\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8415 - loss: 0.4730 - val_accuracy: 0.9100 - val_loss: 0.2819\nEpoch 30/60\n\u001b[1m366/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.4684Validation Accuracy after epoch 30: 0.9097\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8447 - loss: 0.4681 - val_accuracy: 0.9097 - val_loss: 0.2915\nEpoch 31/60\n\u001b[1m371/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.4318Validation Accuracy after epoch 31: 0.9137\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8588 - loss: 0.4318 - val_accuracy: 0.9137 - val_loss: 0.2750\nEpoch 32/60\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.4065Validation Accuracy after epoch 32: 0.9183\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8635 - loss: 0.4066 - val_accuracy: 0.9183 - val_loss: 0.2746\nEpoch 33/60\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 0.3819Validation Accuracy after epoch 33: 0.9163\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8701 - loss: 0.3819 - val_accuracy: 0.9163 - val_loss: 0.2764\nEpoch 34/60\n\u001b[1m371/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8650 - loss: 0.3948Validation Accuracy after epoch 34: 0.9210\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8651 - loss: 0.3948 - val_accuracy: 0.9210 - val_loss: 0.2785\nEpoch 35/60\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.3913Validation Accuracy after epoch 35: 0.9290\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8684 - loss: 0.3913 - val_accuracy: 0.9290 - val_loss: 0.2395\nEpoch 36/60\n\u001b[1m366/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8792 - loss: 0.3569Validation Accuracy after epoch 36: 0.9220\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8792 - loss: 0.3570 - val_accuracy: 0.9220 - val_loss: 0.2468\nEpoch 37/60\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8788 - loss: 0.3468Validation Accuracy after epoch 37: 0.9220\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8788 - loss: 0.3468 - val_accuracy: 0.9220 - val_loss: 0.2545\nEpoch 38/60\n\u001b[1m370/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.3385Validation Accuracy after epoch 38: 0.9250\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8873 - loss: 0.3384 - val_accuracy: 0.9250 - val_loss: 0.2345\nEpoch 39/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.3186Validation Accuracy after epoch 39: 0.9253\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8926 - loss: 0.3186 - val_accuracy: 0.9253 - val_loss: 0.2404\nEpoch 40/60\n\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.3246Validation Accuracy after epoch 40: 0.9307\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8886 - loss: 0.3245 - val_accuracy: 0.9307 - val_loss: 0.2279\nEpoch 41/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8972 - loss: 0.3026Validation Accuracy after epoch 41: 0.9317\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8972 - loss: 0.3026 - val_accuracy: 0.9317 - val_loss: 0.2355\nEpoch 42/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.2779Validation Accuracy after epoch 42: 0.9220\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9064 - loss: 0.2779 - val_accuracy: 0.9220 - val_loss: 0.2744\nEpoch 43/60\n\u001b[1m371/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.3191Validation Accuracy after epoch 43: 0.9333\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8924 - loss: 0.3190 - val_accuracy: 0.9333 - val_loss: 0.2352\nEpoch 44/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.2982Validation Accuracy after epoch 44: 0.9353\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8971 - loss: 0.2981 - val_accuracy: 0.9353 - val_loss: 0.2314\nEpoch 45/60\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2681Validation Accuracy after epoch 45: 0.9330\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9135 - loss: 0.2681 - val_accuracy: 0.9330 - val_loss: 0.2658\nEpoch 46/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9079 - loss: 0.2807Validation Accuracy after epoch 46: 0.9360\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9079 - loss: 0.2806 - val_accuracy: 0.9360 - val_loss: 0.2322\nEpoch 47/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.2575Validation Accuracy after epoch 47: 0.9363\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9158 - loss: 0.2575 - val_accuracy: 0.9363 - val_loss: 0.2133\nEpoch 48/60\n\u001b[1m366/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9216 - loss: 0.2341Validation Accuracy after epoch 48: 0.9403\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9215 - loss: 0.2345 - val_accuracy: 0.9403 - val_loss: 0.2228\nEpoch 49/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9229 - loss: 0.2287Validation Accuracy after epoch 49: 0.9463\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9229 - loss: 0.2288 - val_accuracy: 0.9463 - val_loss: 0.2048\nEpoch 50/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9215 - loss: 0.2307Validation Accuracy after epoch 50: 0.9390\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9214 - loss: 0.2308 - val_accuracy: 0.9390 - val_loss: 0.2161\nEpoch 51/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.2133Validation Accuracy after epoch 51: 0.9353\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9265 - loss: 0.2133 - val_accuracy: 0.9353 - val_loss: 0.2551\nEpoch 52/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9230 - loss: 0.2257Validation Accuracy after epoch 52: 0.9423\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9230 - loss: 0.2257 - val_accuracy: 0.9423 - val_loss: 0.2033\nEpoch 53/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9303 - loss: 0.2046Validation Accuracy after epoch 53: 0.9407\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 0.2047 - val_accuracy: 0.9407 - val_loss: 0.2224\nEpoch 54/60\n\u001b[1m374/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9374 - loss: 0.1830Validation Accuracy after epoch 54: 0.9420\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9373 - loss: 0.1831 - val_accuracy: 0.9420 - val_loss: 0.2018\nEpoch 55/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9339 - loss: 0.2002Validation Accuracy after epoch 55: 0.9423\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9339 - loss: 0.2002 - val_accuracy: 0.9423 - val_loss: 0.2403\nEpoch 56/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.2102Validation Accuracy after epoch 56: 0.9483\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9250 - loss: 0.2102 - val_accuracy: 0.9483 - val_loss: 0.1988\nEpoch 57/60\n\u001b[1m370/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9357 - loss: 0.1873Validation Accuracy after epoch 57: 0.9403\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9357 - loss: 0.1875 - val_accuracy: 0.9403 - val_loss: 0.2259\nEpoch 58/60\n\u001b[1m373/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9329 - loss: 0.2012Validation Accuracy after epoch 58: 0.9473\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9329 - loss: 0.2012 - val_accuracy: 0.9473 - val_loss: 0.1964\nEpoch 59/60\n\u001b[1m372/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 0.1736Validation Accuracy after epoch 59: 0.9510\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9369 - loss: 0.1737 - val_accuracy: 0.9510 - val_loss: 0.1995\nEpoch 60/60\n\u001b[1m368/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.1781Validation Accuracy after epoch 60: 0.9400\n\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9375 - loss: 0.1782 - val_accuracy: 0.9400 - val_loss: 0.2138\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.1788\nTest Accuracy: 0.9400\n","output_type":"stream"}]},{"cell_type":"code","source":"\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T09:09:14.412633Z","iopub.execute_input":"2024-07-05T09:09:14.413671Z","iopub.status.idle":"2024-07-05T09:09:14.449243Z","shell.execute_reply.started":"2024-07-05T09:09:14.413613Z","shell.execute_reply":"2024-07-05T09:09:14.448295Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_13\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d_40 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_40 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_41 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_41 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_42 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m36,928\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_42 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_43 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │        \u001b[38;5;34m36,928\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_43 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_13 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m169\u001b[0m)            │        \u001b[38;5;34m21,801\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">169</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,801</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m737,021\u001b[0m (2.81 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">737,021</span> (2.81 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m245,673\u001b[0m (959.66 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">245,673</span> (959.66 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m491,348\u001b[0m (1.87 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">491,348</span> (1.87 MB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nprint(tf.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T06:16:37.980595Z","iopub.execute_input":"2024-07-05T06:16:37.981517Z","iopub.status.idle":"2024-07-05T06:16:37.986592Z","shell.execute_reply.started":"2024-07-05T06:16:37.981473Z","shell.execute_reply":"2024-07-05T06:16:37.985457Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"2.15.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom PIL import Image\nimport os\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T06:17:22.167303Z","iopub.execute_input":"2024-07-05T06:17:22.167895Z","iopub.status.idle":"2024-07-05T06:17:22.174898Z","shell.execute_reply.started":"2024-07-05T06:17:22.167852Z","shell.execute_reply":"2024-07-05T06:17:22.173543Z"},"trusted":true},"execution_count":8,"outputs":[]}]}